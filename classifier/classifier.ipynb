{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classifier2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "VH1ThGjwpkrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Q6x9vIDNm33H"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import defaultdict\n",
        "\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Setting seeds for reproducability"
      ],
      "metadata": {
        "id": "JX7mY-klqpTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "torch.cuda.manual_seed_all(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# For use in DataLoader:\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "g = torch.Generator()\n",
        "g.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxfwB9r4yKd_",
        "outputId": "79e50ed8-de77-4b34-a5fa-a938e6cc8f73"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7ff9f99dc1f0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EvidenceTypeDataset(Dataset):\n",
        "\n",
        "    def __init__(self, thread_id, comment_id, sentence, target, tokenizer, max_len):\n",
        "        self.thread_id = thread_id\n",
        "        self.comment_id = comment_id\n",
        "        self.sentence = sentence\n",
        "        self.targets = target\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentence)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        sentence = str(self.sentence[item])\n",
        "        thread_id = str(self.thread_id[item])\n",
        "        comment_id = str(self.comment_id[item])\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            sentence,\n",
        "            max_length=self.max_len,\n",
        "            add_special_tokens=True,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_token_type_ids=False,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'thread_id': thread_id,\n",
        "            'comment_id': comment_id,\n",
        "            'sentence_text': sentence,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'targets': torch.tensor(self.targets[item], dtype=torch.long)\n",
        "        }"
      ],
      "metadata": {
        "id": "VZrJubfMnJ_N"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EvidenceTypeClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes, model_name, pretrained_model_name):\n",
        "        super(EvidenceTypeClassifier, self).__init__()\n",
        "        \n",
        "        self.bert = model_name.from_pretrained(pretrained_model_name, return_dict=False)\n",
        "        self.drop = nn.Dropout()\n",
        "        self.out = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        _, pooled_output = self.bert(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "        output = self.drop(pooled_output)\n",
        "        return self.out(output)"
      ],
      "metadata": {
        "id": "8PqzMHdZnN8F"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "    return DataLoader(\n",
        "        EvidenceTypeDataset(\n",
        "            thread_id=df.thread_id.to_numpy(),\n",
        "            comment_id=df.comment_id.to_numpy(),\n",
        "            sentence=df.sentence.to_numpy(),\n",
        "            target=df.label_int.to_numpy(),\n",
        "            tokenizer=tokenizer,\n",
        "            max_len=max_len\n",
        "        ),\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=g,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=4\n",
        "    )"
      ],
      "metadata": {
        "id": "mgmABzG9nPjU"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, data_loader, loss_function, optimizer, scheduler, num_examples, device):\n",
        "    model = model.train()\n",
        "    losses = []\n",
        "    predictions = []\n",
        "    real_values = []\n",
        "    correct_predictions = 0\n",
        "\n",
        "    for d in data_loader:\n",
        "        input_ids = d['input_ids'].to(device)\n",
        "        attention_mask = d['attention_mask'].to(device)\n",
        "        targets = d['targets'].to(device)\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        " \n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "        loss = loss_function(outputs, targets)\n",
        "\n",
        "        predictions.extend(preds)\n",
        "        real_values.extend(targets)\n",
        "\n",
        "        correct_predictions += torch.sum(preds == targets)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    predictions = torch.stack(predictions).cpu()\n",
        "    real_values = torch.stack(real_values).cpu()\n",
        "    f1 = f1_score(real_values, predictions, average='weighted')\n",
        "\n",
        "    return correct_predictions.double() / num_examples, np.mean(losses), f1"
      ],
      "metadata": {
        "id": "IxFzQ7-JnRWJ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, data_loader, loss_function, num_examples, device):\n",
        "    model = model.eval()\n",
        "    losses = []\n",
        "    predictions = []\n",
        "    real_values = []\n",
        "    correct_predictions = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for d in data_loader:\n",
        "            input_ids = d['input_ids'].to(device)\n",
        "            attention_mask = d['attention_mask'].to(device)\n",
        "            targets = d['targets'].to(device)\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask\n",
        "            )\n",
        "\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "            loss = loss_function(outputs, targets)\n",
        "\n",
        "            predictions.extend(preds)\n",
        "            real_values.extend(targets)\n",
        "\n",
        "            correct_predictions += torch.sum(preds == targets)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "    predictions = torch.stack(predictions).cpu()\n",
        "    real_values = torch.stack(real_values).cpu()\n",
        "    f1 = f1_score(real_values, predictions, average='weighted')\n",
        "\n",
        "    return correct_predictions.double() / num_examples, np.mean(losses), f1"
      ],
      "metadata": {
        "id": "gtTs9c9ZnT2B"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_best_model(model, loss_function, df_train, df_val, tokenizer, max_len,\n",
        "                    batch_size, num_epochs, device, print_graph=True, \n",
        "                    save_file_name='model_state', save_models='last'):\n",
        "  \n",
        "    \"\"\"\"save_models can be 'all', 'best' or 'last'\"\"\"\n",
        "\n",
        "    train_data_loader = create_data_loader(df_train, tokenizer, max_len, batch_size)\n",
        "    val_data_loader = create_data_loader(df_val, tokenizer, max_len, batch_size)\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=True, no_deprecation_warning=True)\n",
        "\n",
        "    total_steps = len(train_data_loader) * num_epochs\n",
        "\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, \n",
        "        num_warmup_steps=0,\n",
        "        num_training_steps=total_steps\n",
        "    )\n",
        "\n",
        "    history = defaultdict(list)\n",
        "    best_f1 = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
        "        print('-' * 56)\n",
        "\n",
        "        training_accuracy, training_loss, training_f1 = train_model(\n",
        "            model,\n",
        "            train_data_loader,\n",
        "            loss_function,\n",
        "            optimizer,\n",
        "            scheduler,\n",
        "            len(df_train),\n",
        "            device\n",
        "        )\n",
        "\n",
        "        print('Training:   loss {:.3f} - accuracy {:.3f} - f1-score {:.3f}'.format(training_loss, training_accuracy, training_f1))\n",
        "\n",
        "        validation_accuracy, validation_loss, validation_f1 = evaluate_model(\n",
        "            model,\n",
        "            val_data_loader,\n",
        "            loss_function,\n",
        "            len(df_val),\n",
        "            device\n",
        "        )\n",
        "\n",
        "        print('Validation: loss {:.3f} - accuracy {:.3f} - f1-score {:.3f}\\n'.format(validation_loss, validation_accuracy, validation_f1))\n",
        "\n",
        "        history['training_accuracy'].append(training_accuracy.cpu().item())\n",
        "        history['training_loss'].append(training_loss)\n",
        "        history['training_f1'].append(training_f1)\n",
        "\n",
        "        history['validation_accuracy'].append(validation_accuracy.cpu().item())\n",
        "        history['validation_loss'].append(validation_loss)\n",
        "        history['validation_f1'].append(validation_f1)\n",
        "\n",
        "        if save_models == 'all':\n",
        "            torch.save(model.state_dict(), save_file_name+\"_\"+str(epoch+1)+\".bin\")\n",
        "        elif save_models == 'best':\n",
        "            if validation_f1 > best_f1:\n",
        "                torch.save(model.state_dict(), 'best_model_state.bin')\n",
        "                best_f1 = validation_f1\n",
        "        elif save_models == 'last':\n",
        "            if epoch == num_epochs:\n",
        "                torch.save(model.state_dict(), 'last_model_state.bin')\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "JI4DQkKHnV0u"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(model, data_loader, label_encoder, device, save_predictions=True, save_file_name='predictions.csv'):\n",
        "    model = model.eval()\n",
        "    thread_id_list = []\n",
        "    comment_id_list = []\n",
        "    sentence_texts = []\n",
        "    predictions = []\n",
        "    real_values = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for d in data_loader:\n",
        "            thread_ids = d['thread_id']\n",
        "            comment_ids = d['comment_id']\n",
        "            texts = d[\"sentence_text\"]\n",
        "            input_ids = d[\"input_ids\"].to(device)\n",
        "            attention_mask = d[\"attention_mask\"].to(device)\n",
        "            targets = d[\"targets\"].to(device)\n",
        "            outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "            )\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "            thread_id_list.extend(thread_ids)\n",
        "            comment_id_list.extend(comment_ids)\n",
        "            sentence_texts.extend(texts)\n",
        "            predictions.extend(preds)\n",
        "            real_values.extend(targets)\n",
        "    \n",
        "    predictions = torch.stack(predictions).cpu()\n",
        "    real_values = torch.stack(real_values).cpu()\n",
        "\n",
        "    if save_predictions:\n",
        "        df_pred = pd.DataFrame()\n",
        "        df_pred['thread_id'] = thread_id_list\n",
        "        df_pred['comment_id'] = comment_id_list\n",
        "        df_pred['sentence'] = sentence_texts\n",
        "        df_pred['pred_label'] = label_encoder.inverse_transform(predictions)\n",
        "        df_pred['real_label'] = label_encoder.inverse_transform(real_values)\n",
        "\n",
        "        df_pred.to_csv(save_file_name, index=False)\n",
        "\n",
        "    return thread_id_list, comment_id_list, sentence_texts, predictions, real_values"
      ],
      "metadata": {
        "id": "psgruWhOnYVA"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load in data"
      ],
      "metadata": {
        "id": "TH_-2_eoFIIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_ids = ['t3_6rwcio', 't3_5jfqhp', 't3_71l9yj', 't3_4mj8v7', 't3_58t7i3',\n",
        "            't3_64kkxe', 't3_6ihcuk', 't3_5o7nm3', 't3_4tf91m', 't3_4q9qng']\n",
        "val_ids = ['t3_5ep0mh', 't3_4pbwvb', 't3_4g3nbn', 't3_6tsx1p', 't3_62igvv',\n",
        "           't3_6694ui', 't3_6h7a4i', 't3_4plwqq', 't3_4otmqi', 't3_57tl4k']\n",
        "\n",
        "df = pd.read_csv('final_dataset.csv')\n",
        "df.columns = ['sentence', 'original_label', 'thread_id', 'comment_id', 'label']\n",
        "\n",
        "df_train = df[~(df['thread_id'].isin((test_ids + val_ids)))]\n",
        "df_val = df[df['thread_id'].isin(val_ids)]\n",
        "df_test = df[df['thread_id'].isin(test_ids)]\n",
        "\n",
        "# Transform labels to integers\n",
        "label_encoder = LabelEncoder()\n",
        "df_train['label_int'] = label_encoder.fit_transform(df_train['label'])\n",
        "df_val['label_int'] = label_encoder.fit_transform(df_val['label'])\n",
        "df_test['label_int'] = label_encoder.fit_transform(df_test['label'])"
      ],
      "metadata": {
        "id": "r5OVMdWEFKYM"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Instantiate models\n",
        "\n",
        "##### General settings"
      ],
      "metadata": {
        "id": "TA8m3QazFJtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class_weights = (1 - (df['label_int'].value_counts().sort_index() / len(df))).values\n",
        "class_weights = torch.from_numpy(class_weights).float().to(device)\n",
        "\n",
        "num_classes = len(df['label'].unique())\n",
        "loss_function = nn.CrossEntropyLoss(weight=class_weights).to(device)\n",
        "\n",
        "max_len = 128\n",
        "batch_size = 32\n",
        "num_epochs = 50\n",
        "\n",
        "model_name = BertModel"
      ],
      "metadata": {
        "id": "6dIYgb_gLC-0"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### BERT"
      ],
      "metadata": {
        "id": "Q-WgJn7WLANr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_bert = AutoTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "syO0rRMpLZtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Fine-tune pretrained model and saving training history\n",
        "\n",
        "###### Uncomment to fine-tune\n",
        "\n"
      ],
      "metadata": {
        "id": "8NYkiTxRLdDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_bert = EvidenceTypeClassifier(num_classes, model_name, 'bert-base-uncased')\n",
        "model_bert = model_bert.to(device)\n",
        "training_history_bert = find_best_model(model_bert, loss_function, df_train, df_val, tokenizer_bert, max_len, batch_size, num_epochs, device)\n",
        "\n",
        "history_df_bert = pd.DataFrame()\n",
        "history_df_bert['training_accuracy'] = training_history_bert['training_accuracy']\n",
        "history_df_bert['training_f1'] = training_history_bert['training_f1']\n",
        "history_df_bert['training_loss'] = training_history_bert['training_loss']\n",
        "history_df_bert['validation_accuracy'] = training_history_bert['validation_accuracy']\n",
        "history_df_bert['validation_f1'] = training_history_bert['validation_f1']\n",
        "history_df_bert['validation_loss'] = training_history_bert['validation_loss']\n",
        "history_df_bert.index += 1\n",
        "history_df_bert.to_csv('training_history_bert.csv', index_label='epoch')"
      ],
      "metadata": {
        "id": "SH9OgoYRLcXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load in fine-tuned pretrained model state and predict labels on test set"
      ],
      "metadata": {
        "id": "LEs_9UvLVi4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_loader = create_data_loader(df_test, tokenizer_bert, max_len, batch_size)\n",
        "\n",
        "model = EvidenceTypeClassifier(num_classes, model_name, 'bert-base-uncased')\n",
        "model.load_state_dict(torch.load('fine_tuned_model_state.bin'))\n",
        "model = model.to(device)\n",
        "\n",
        "thread_ids, comment_ids, y_sentence_texts, y_pred, y_test = get_predictions(\n",
        "    model,\n",
        "    test_data_loader,\n",
        "    label_encoder,\n",
        "    device,\n",
        "    save_file_name='predictions_bert.csv'\n",
        "    )\n",
        "\n",
        "y_test = label_encoder.inverse_transform(y_test)\n",
        "y_pred = label_encoder.inverse_transform(y_pred)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "kRVOWulOnaa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### MiniLM"
      ],
      "metadata": {
        "id": "DE9rVROCaPT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_minilm = AutoTokenizer.from_pretrained('microsoft/MiniLM-L12-H384-uncased')"
      ],
      "metadata": {
        "id": "0df0m5f6aSXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Fine-tune pretrained model and saving training history\n",
        "\n",
        "###### Uncomment to fine-tune"
      ],
      "metadata": {
        "id": "yb4NOUjaac0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_minilm = EvidenceTypeClassifier(num_classes, model_name, 'microsoft/MiniLM-L12-H384-uncased')\n",
        "model_minilm = model_minilm.to(device)\n",
        "training_history_minilm = find_best_model(model_minilm, loss_function, df_train, df_val, tokenizer_minilm, max_len, batch_size, num_epochs, device)\n",
        "\n",
        "history_df_minilm = pd.DataFrame()\n",
        "history_df_minilm['training_accuracy'] = training_history_minilm['training_accuracy']\n",
        "history_df_minilm['training_f1'] = training_history_minilm['training_f1']\n",
        "history_df_minilm['training_loss'] = training_history_minilm['training_loss']\n",
        "history_df_minilm['validation_accuracy'] = training_history_minilm['validation_accuracy']\n",
        "history_df_minilm['validation_f1'] = training_history_minilm['validation_f1']\n",
        "history_df_minilm['validation_loss'] = training_history_minilm['validation_loss']\n",
        "history_df_minilm.index += 1\n",
        "history_df_minilm.to_csv('training_history_minilm.csv', index_label='epoch')"
      ],
      "metadata": {
        "id": "5q7HA8b8afcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load in fine-tuned pretrained model state and predict labels on test set"
      ],
      "metadata": {
        "id": "23xgz4b3bWjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_loader = create_data_loader(df_test, tokenizer_minilm, max_len, batch_size)\n",
        "\n",
        "model = EvidenceTypeClassifier(num_classes, model_name, 'microsoft/MiniLM-L12-H384-uncased')\n",
        "model.load_state_dict(torch.load('fine_tuned_model_state.bin'))\n",
        "model = model.to(device)\n",
        "\n",
        "thread_ids, comment_ids, y_sentence_texts, y_pred, y_test = get_predictions(\n",
        "    model,\n",
        "    test_data_loader,\n",
        "    label_encoder,\n",
        "    device,\n",
        "    save_file_name='predictions_minilm.csv'\n",
        "    )\n",
        "\n",
        "y_test = label_encoder.inverse_transform(y_test)\n",
        "y_pred = label_encoder.inverse_transform(y_pred)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "ODmqPyaNbZLG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}